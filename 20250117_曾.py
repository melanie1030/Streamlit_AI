import streamlit as st
from openai import OpenAI
import pandas as pd
import dotenv  # ç”¨æ–¼åŠ è¼‰ç’°å¢ƒè®Šé‡
import os
from PIL import Image  # ç”¨æ–¼åœ–åƒè™•ç†
import base64  # ç”¨æ–¼Base64ç·¨ç¢¼/è§£ç¢¼
from io import BytesIO  # ç”¨æ–¼è™•ç†äºŒé€²åˆ¶æ•¸æ“š
import random  # ç”¨æ–¼ç”Ÿæˆéš¨æ©Ÿæ•¸
import numpy as np
import tempfile
import json
import io
import sys


# åŠ è¼‰ç’°å¢ƒè®Šé‡ï¼ˆæ¯”å¦‚APIå¯†é‘°ï¼‰
dotenv.load_dotenv()

# å®šç¾©å¯ç”¨çš„OpenAIæ¨¡å‹åˆ—è¡¨
openai_models = [
    "gpt-4o", 
    "gpt-4-turbo", 
    "gpt-3.5-turbo-16k", 
    "gpt-4", 
    "gpt-4-32k",
]

# åœ¨å´é‚Šæ¬„æ–°å¢è³‡æ–™è¼¸å…¥å’Œä¿å­˜åŠŸèƒ½ï¼Œä¸¦åŠ å…¥æŠ˜ç–ŠæŒ‰éˆ•
def save_data_as_csv():
    with st.expander("é»æ“Šå±•é–‹ä»¥è¼¸å…¥è³‡æ–™ä¸¦ç”Ÿæˆ CSV æª”æ¡ˆ"):
        input_data = st.text_area("ç”Ÿæˆ CSV æª”æ¡ˆ (è«‹è¼¸å…¥è³‡æ–™):", height=200)
        
        if input_data:
            try:
                # å°‡è¼¸å…¥è³‡æ–™è™•ç†ç‚ºè¡¨æ ¼
                rows = input_data.strip().split("\n")
                data = [row.split(",") for row in rows]

                # å»ºç«‹è³‡æ–™æ¡†æ¶
                df = pd.DataFrame(data[1:], columns=data[0])
                st.write("è³‡æ–™é è¦½:", df)

                # æä¾›ä¿å­˜åŠŸèƒ½
                if st.button("ä¿å­˜ç‚º CSV æª”æ¡ˆ"):
                    csv_buffer = io.StringIO()
                    df.to_csv(csv_buffer, index=False)
                    csv_buffer.seek(0)
                    
                    # ä¸‹è¼‰æŒ‰éˆ•
                    st.download_button(
                        label="ä¸‹è¼‰ CSV æª”æ¡ˆ",
                        data=csv_buffer.getvalue(),
                        file_name="saved_data.csv",
                        mime="text/csv",
                    )
            except Exception as e:
                st.error(f"è³‡æ–™è™•ç†éŒ¯èª¤: {str(e)}")

def execute_code_and_generate_images(code: str, uploaded_file=None):
    try:
        if uploaded_file:
            if uploaded_file.type == "text/csv":
                dataset = pd.read_csv(uploaded_file)  
                globals()['dataset'] = dataset  
            else:
                st.error("åªæ”¯æ´CSVæª”æ¡ˆ")
                return

        import matplotlib.pyplot as plt
        import io

        captured_output = io.StringIO()  
        sys.stdout = captured_output  

        exec(code, globals())  

        sys.stdout = sys.__stdout__

        print_output = captured_output.getvalue()

        image_buffers = []
        figures = [plt.figure(i) for i in plt.get_fignums()]

        for fig in figures:
            buf = io.BytesIO()
            fig.savefig(buf, format="png")  
            buf.seek(0)
            image_buffers.append(buf)

        plt.close('all')

        return print_output, image_buffers

    except Exception as e:
        st.error(f"ç¨‹å¼ç¢¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}")  # é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯
        return None, None

def stream_llm_response(model_params, model_type="openai", api_key=None, uploaded_file=None):
    response_message = ""
    
    try:
        prompt_instructions = """
        ç•¶ä½ ç·¨å¯«ç¨‹å¼ç¢¼æ™‚ï¼Œè«‹å§‹çµ‚ä½¿ç”¨è®Šæ•¸ `dataset` ä¾†è™•ç†è³‡æ–™é›†ï¼Œä¸¦é¿å…åˆ—å°æ•¸æ“šé›†çš„æ•¸æ“šï¼Œæ¬„ä½åç¨±å¯ä»¥ã€‚
        """
        
        dataset_info = ""
        if "dataset" in globals() and isinstance(globals()['dataset'], pd.DataFrame):
            try:
                columns = ", ".join(globals()['dataset'].columns[:100])  
                dataset_info = f"è³‡æ–™é›†åŒ…å« {globals()['dataset'].shape[0]} è¡Œå’Œ {globals()['dataset'].shape[1]} åˆ—ã€‚\næ¬„ä½åç¨±ï¼š{columns}"
            except Exception as e:
                st.error(f"æ•¸æ“šè½‰æ›éŒ¯èª¤: {e}")

        if dataset_info:
            st.session_state.messages.append(
                {"role": "user", "content": f"ä»¥ä¸‹æ˜¯ä¸Šå‚³çš„æ•¸æ“šï¼š\n{dataset_info}"}
            )
        
        client = OpenAI(api_key=api_key)
        for chunk in client.chat.completions.create(
            model=model_params["model"],
            messages=[{"role": "system", "content": prompt_instructions}] + st.session_state.messages,
            temperature=model_params["temperature"],
            max_tokens=4096,
            stream=True,
        ):
            chunk_text = chunk.choices[0].delta.content or ""
            response_message += chunk_text
            yield chunk_text

        if "```python" in response_message:
            code_start = response_message.find("```python") + len("```python")
            code_end = response_message.find("```", code_start)
            code = response_message[code_start:code_end].strip()

            print_output, image_buffers = execute_code_and_generate_images(code, uploaded_file)

            if print_output:
                if "ç¨‹å¼ç¢¼åŸ·è¡ŒéŒ¯èª¤" in print_output:
                    st.error(print_output)
                else:
                    with st.expander("ç¨‹å¼ç¢¼è¼¸å‡º (é»æ“Šå±•é–‹)"):
                        st.text_area("ç¨‹å¼ç¢¼è¼¸å‡º:", value=print_output, height=200)
                
            if isinstance(image_buffers, list):
                for idx, buf in enumerate(image_buffers):
                    with st.expander(f"åœ–è¡¨ {idx + 1} (é»æ“Šæª¢è¦–)"):
                        st.image(buf, caption=f"ç”Ÿæˆçš„åœ–è¡¨ {idx + 1}", use_container_width=True)
            else:
                st.error(f"åŸ·è¡Œç¨‹å¼ç¢¼æ™‚å‡ºç¾éŒ¯èª¤ï¼š{image_buffers}")

    except Exception as e:
        st.error(f"å›æ‡‰è™•ç†éŒ¯èª¤: {str(e)}")  # é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯


# å°‡åœ–åƒè½‰æ›ç‚ºBase64ç·¨ç¢¼çš„å‡½æ•¸
def get_image_base64(image_raw):
    buffered = BytesIO()
    image_raw.save(buffered, format=image_raw.format)
    img_byte = buffered.getvalue()
    return base64.b64encode(img_byte).decode('utf-8')

# å°‡æ–‡ä»¶è½‰æ›ç‚ºBase64ç·¨ç¢¼çš„å‡½æ•¸
def file_to_base64(file):
    with open(file, "rb") as f:
        return base64.b64encode(f.read())

# å°‡Base64ç·¨ç¢¼è½‰æ›å›åœ–åƒçš„å‡½æ•¸
def base64_to_image(base64_string):
    base64_string = base64_string.split(",")[1]
    return Image.open(BytesIO(base64.b64decode(base64_string)))

# ä¸»å‡½æ•¸
def main():
    # --- é é¢é…ç½® ---
    st.set_page_config(
        page_title="Chatbot",
        page_icon="ğŸ¤–",
        layout="centered",
        initial_sidebar_state="expanded",
    )

    # --- é é¢æ¨™é¡Œ ---
    st.html("""<h1 style="text-align: center; color: #6ca395;"><i>Openai Chatbot</i> </h1>""")

    # --- å´é‚Šæ¬„è¨­ç½® ---
    with st.sidebar:
        cols_keys = st.columns(2)
        with cols_keys[0]:
            # ç²å–é è¨­çš„OpenAI APIå¯†é‘°ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
            default_openai_api_key = os.getenv("OPENAI_API_KEY") if os.getenv("OPENAI_API_KEY") is not None else ""
            with st.popover("ğŸ” API_KEY"):
                openai_api_key = st.text_input("Introduce your OpenAI API Key (https://platform.openai.com/)", 
                                             value=default_openai_api_key, 
                                             type="password")

    # --- ä¸»è¦å…§å®¹ ---
    # æª¢æŸ¥ç”¨æˆ¶æ˜¯å¦è¼¸å…¥äº†APIå¯†é‘°
    if (openai_api_key == "" or openai_api_key is None or "sk-" not in openai_api_key):
        st.write("#")
        st.warning("â¬…ï¸ Please introduce an API Key to continue...")
    
    else:
        client = OpenAI(api_key=openai_api_key)  # å‰µå»ºOpenAIå®¢æˆ¶ç«¯

        # åˆå§‹åŒ–èŠå¤©è¨˜éŒ„
        if "messages" not in st.session_state:
            st.session_state.messages = []  # åˆå§‹åŒ–ç©ºåˆ—è¡¨å„²å­˜æ­·å²è¨Šæ¯

        # é¡¯ç¤ºä¹‹å‰çš„èŠå¤©è¨˜éŒ„ï¼Œä¸¦ç¢ºä¿æ¯æ¢è¨Šæ¯åªæ¸²æŸ“ä¸€æ¬¡
        if "rendered_messages" not in st.session_state:
            st.session_state.rendered_messages = set()  # ç´€éŒ„å·²æ¸²æŸ“çš„è¨Šæ¯

        # é¡¯ç¤ºèŠå¤©è¨˜éŒ„
        for idx, message in enumerate(st.session_state.messages):
            # é¡¯ç¤ºç”¨æˆ¶è¨Šæ¯
            if message["role"] == "user":
                with st.chat_message("user"):
                    # ç¢ºä¿ message["content"] æ˜¯åˆ—è¡¨ä¸¦ä¸”åŒ…å«å­—å…¸
                    if isinstance(message["content"], list) and len(message["content"]) > 0:
                        st.markdown(message["content"][0].get("text", ""))  # ä½¿ç”¨ get é¿å… KeyError
            # é¡¯ç¤º AI å›æ‡‰
            elif message["role"] == "assistant":
                with st.chat_message("assistant"):
                    # ç¢ºä¿ message["content"] æ˜¯åˆ—è¡¨ä¸¦ä¸”åŒ…å«å­—å…¸
                    if isinstance(message["content"], list) and len(message["content"]) > 0:
                        st.markdown(message["content"][0].get("text", ""))  # ä½¿ç”¨ get é¿å… KeyError
                        
            # å°‡å·²æ¸²æŸ“çš„è¨Šæ¯ç´¢å¼•æ·»åŠ åˆ°ç´€éŒ„            
            st.session_state.rendered_messages.add(idx)

        # --- å´é‚Šæ¬„æ¨¡å‹é¸é …å’Œè¼¸å…¥ ---
        with st.sidebar:
            st.divider()
            
            # é¡¯ç¤ºå¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
            available_models = [] + (openai_models if openai_api_key else [])
            model = st.selectbox("Select a model:", available_models, index=0)
            model_type = None
            if model.startswith("gpt"): model_type = "openai"
            
            # æ¨¡å‹åƒæ•¸è¨­ç½®
            with st.popover("âš™ï¸ Model parameters"):
                model_temp = st.slider("Temperature", min_value=0.0, max_value=2.0, value=0.3, step=0.1)

            # è¨­ç½®æ¨¡å‹åƒæ•¸
            model_params = {
                "model": model,
                "temperature": model_temp,
            }

            # é‡ç½®å°è©±åŠŸèƒ½
            def reset_conversation():
                if "messages" in st.session_state and len(st.session_state.messages) > 0:
                    st.session_state.pop("messages", None)

            st.button("ğŸ—‘ï¸", on_click=reset_conversation)

            st.divider()
            
            # è®€å–æ–‡ä»¶å…§å®¹ä¸¦è¿”å›ç‚ºæ–‡æœ¬
            def read_file_content(file):
                if file.type == "application/pdf":
                    from PyPDF2 import PdfReader
                    reader = PdfReader(file)
                    text = ""
                    for page in reader.pages:
                        text += page.extract_text()
                    return text

                elif file.type == "text/plain":
                    return file.getvalue().decode("utf-8")

                elif file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                    from docx import Document
                    doc = Document(file)
                    text = "\n".join([para.text for para in doc.paragraphs])
                    return text

                elif file.type == "text/csv":
                    # ä½¿ç”¨ Pandas è™•ç† CSV æ–‡ä»¶
                    try:
                        file_content = pd.read_csv(file)
                        st.write("### æ•¸æ“šé è¦½:")
                        st.dataframe(file_content)  # é¡¯ç¤ºæ•¸æ“šæ¡†
                        # å°‡è³‡æ–™é›†è¨­å®šç‚ºå…¨åŸŸè®Šæ•¸ï¼Œä¾›å¾ŒçºŒç¨‹å¼ç¢¼ä½¿ç”¨
                        globals()['dataset'] = file_content
                        st.success("CSV æª”æ¡ˆå·²æˆåŠŸä¸Šå‚³ï¼")
                        return "CSV æ–‡ä»¶å·²è¼‰å…¥ï¼Œè«‹åœ¨ç¨‹å¼ç¢¼ä¸­ä½¿ç”¨ `dataset` è®Šæ•¸é€²è¡Œæ“ä½œã€‚"
                    except Exception as e:
                        st.error(f"CSV æ–‡ä»¶è™•ç†å‡ºéŒ¯: {e}")
                        return None

                elif file.type == "application/vnd.openxmlformats-officedocument.presentationml.presentation":
                    from pptx import Presentation
                    prs = Presentation(file)
                    text = ""
                    for slide in prs.slides:
                        for shape in slide.shapes:
                            if hasattr(shape, "text"):
                                text += shape.text + "\n"
                    return text
                return None
            
            # åœ¨å´é‚Šæ¬„ä¸­æ·»åŠ æª”æ¡ˆä¸Šå‚³é¸é …
            with st.sidebar:
                st.write("### **Upload a file**:")
                uploaded_file = st.file_uploader(
                    "Upload a file (.txt, .pdf, .docx, .csv, .pptx):", 
                    type=["txt", "pdf", "docx", "csv", "pptx"],
                    accept_multiple_files=False,
                    key="uploaded_file"
                )

                if uploaded_file:
                    file_content = read_file_content(uploaded_file)
                    if file_content:
                        # å°‡æ–‡ä»¶å…§å®¹æ·»åŠ åˆ°èŠå¤©è¨˜éŒ„
                        st.session_state.messages.append(
                            {
                                "role": "user", 
                                "content": [{
                                    "type": "text",  
                                    "text": file_content,
                                }]
                            }
                        )
                    model2key = {
                        "openai": openai_api_key,
                    }
                    image_buffers = stream_llm_response(model_params=model_params,
                                            model_type=model_type,
                                            api_key=model2key[model_type],
                                            uploaded_file=uploaded_file)
            
            # æ”¾ç½®åœ¨å´é‚Šæ¬„ä¸­
            with st.sidebar:
                save_data_as_csv()
                
        # --- èŠå¤©è¼¸å…¥è™•ç† ---
        if prompt := st.chat_input("Hi! Ask me anything..."):
            # å°‡ç”¨æˆ¶è¼¸å…¥åŠ å…¥èŠå¤©è¨˜éŒ„
            st.session_state.messages.append(
                {"role": "user", "content": [{"type": "text", "text": prompt}]}
            )
            # æ¸²æŸ“ç”¨æˆ¶è¨Šæ¯
            with st.chat_message("user"):
                st.markdown(prompt)

            # å‘¼å« GPT æ¨¡å‹ï¼Œç”Ÿæˆå›æ‡‰
            with st.chat_message("assistant"):
                model2key = {
                    "openai": openai_api_key,
                }
                response_text = ""
                assistant_placeholder = st.empty()
                for chunk in stream_llm_response(
                    model_params=model_params,
                    model_type=model_type,
                    api_key=model2key[model_type]
                ):
                    response_text += chunk
                    assistant_placeholder.markdown(response_text)

                # å°‡ AI å›æ‡‰åŠ å…¥èŠå¤©è¨˜éŒ„
                st.session_state.messages.append(
                    {"role": "assistant", "content": [{"type": "text", "text": response_text}]}
                )


# ç¨‹å¼å…¥å£é»
if __name__=="__main__":
    main()
