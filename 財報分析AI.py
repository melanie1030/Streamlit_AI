import streamlit as st
import os
import tempfile
import fitz  # PyMuPDF
import pdfplumber  # æå–è¡¨æ ¼
from pdf2image import convert_from_path
import pytesseract
from PIL import Image
from openai import OpenAI  # æ›´æ–°å¾Œçš„ OpenAI èª¿ç”¨æ–¹å¼

# è¨­å®š Tesseract OCR çš„è·¯å¾‘ï¼ˆWindows ç”¨æˆ¶è«‹ä¿®æ”¹è·¯å¾‘ï¼‰
pytesseract.pytesseract.tesseract_cmd = r"C:\\Program Files\\Tesseract-OCR\\tesseract.exe"

# è¨­å®š Poppler çš„è·¯å¾‘ï¼ˆç”¨æˆ¶è‡ªè¨‚ï¼‰
POPPLER_PATH = r"C:\\Program Files\\poppler-24.08.0\\Library\\bin"

# å°‡æ–‡æœ¬åˆ†æ®µä»¥é¿å… Token è¶…é™
def split_text(text, max_tokens=8000):
    paragraphs = text.split("\n\n")
    current_chunk = ""
    chunks = []

    for para in paragraphs:
        if len(current_chunk) + len(para) < max_tokens:
            current_chunk += para + "\n\n"
        else:
            chunks.append(current_chunk)
            current_chunk = para + "\n\n"
    if current_chunk:
        chunks.append(current_chunk)

    return chunks

def save_text_as_txt(text, filename="ocr_result.txt"):
    """ å°‡å­—ä¸²å­˜æˆ TXT æª”æ¡ˆä¸¦æä¾›ä¸‹è¼‰ """
    temp_path = os.path.join(tempfile.gettempdir(), filename)
    with open(temp_path, "w", encoding="utf-8") as file:
        file.write(text)

    with open(temp_path, "rb") as file:
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ OCR è§£æçµæœ",
            data=file,
            file_name=filename,
            mime="text/plain"
        )

def extract_text_with_ocr(pdf_path):
    """ æ··åˆ PDF æ–‡å­—æå–èˆ‡ OCRï¼Œä¸¦å„ªåŒ–è¡¨æ ¼è­˜åˆ¥ """
    doc = fitz.open(pdf_path)
    full_text = ""

    with pdfplumber.open(pdf_path) as pdf:
        for i, page in enumerate(pdf.pages):
            text = page.extract_text()
            tables = page.extract_tables()

            if text:
                full_text += f"--- ç¬¬ {i+1} é  ---\n{text}\n\n"

            if tables:
                for table in tables:
                    formatted_table = "\n".join(
                        [" | ".join(str(cell) if cell is not None else "" for cell in row) for row in table]
                    )
                    full_text += f"--- è¡¨æ ¼ï¼ˆç¬¬ {i+1} é ï¼‰---\n{formatted_table}\n\n"

    for page in doc:
        if not page.get_text("text").strip():
            images = convert_from_path(
                pdf_path, first_page=page.number+1, last_page=page.number+1, poppler_path=POPPLER_PATH
            )
            for img in images:
                ocr_text = pytesseract.image_to_string(
                    img, lang="eng+chi_tra", config="--psm 6"
                )
                full_text += f"--- OCR è§£æï¼ˆç¬¬ {page.number+1} é ï¼‰---\n{ocr_text}\n\n"

    return full_text

def vector_embedding(uploaded_files):
    if "vectors" not in st.session_state:
        all_docs = []
        combined_text = ""

        for uploaded_file in uploaded_files:
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
                    temp_file.write(uploaded_file.read())
                    temp_file_path = temp_file.name

                extracted_text = extract_text_with_ocr(temp_file_path)
                os.remove(temp_file_path)

                combined_text += extracted_text + "\n\n"
                all_docs.append(extracted_text)
            except Exception as e:
                st.error(f"è™•ç†æ–‡ä»¶ {uploaded_file.name} æ™‚å‡ºéŒ¯: {e}")
                continue

        st.session_state.vectors = combined_text
        save_text_as_txt(combined_text)

if "api_key" not in st.session_state:
    st.session_state.api_key = ""

st.sidebar.header("Settings")

if "messages" not in st.session_state:
    st.session_state.messages = []
if "thinking_protocol" not in st.session_state:
    st.session_state.thinking_protocol = None

OPENAI_MODELS = [
    "gpt-4-turbo", 
    "gpt-3.5-turbo-16k",
    "gpt-4",
    "gpt-4-32k",
    "gpt-4o"
]

st.sidebar.subheader("é¸æ“‡æ¨¡å‹")
selected_model = st.sidebar.selectbox("è«‹é¸æ“‡æ¨¡å‹", OPENAI_MODELS, index=0)

st.session_state.selected_model = selected_model

if st.sidebar.button("ğŸ—‘ï¸ æ¸…é™¤è¨˜æ†¶"):
    st.session_state.memory = []
    st.session_state.messages = []
    st.session_state.thinking_protocol = None
    st.sidebar.success("è¨˜æ†¶å·²æ¸…é™¤ï¼")

st.sidebar.subheader("ğŸ§  è¨˜æ†¶ç‹€æ…‹")
if st.session_state.messages:
    memory_content = "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.messages])
    st.sidebar.text_area("ç•¶å‰è¨˜æ†¶", value=memory_content, height=200)
else:
    st.sidebar.text_area("ç•¶å‰è¨˜æ†¶", value="å°šç„¡è¨Šæ¯ã€‚", height=200)

st.sidebar.subheader("ğŸ§  ä¸Šå‚³ Thinking Protocol")
uploaded_thinking_protocol = st.sidebar.file_uploader(
    "é¸æ“‡ thinking_protocol.md æª”æ¡ˆ:", type=["md"], key="thinking_protocol_uploader"
)
if uploaded_thinking_protocol:
    try:
        thinking_protocol_content = uploaded_thinking_protocol.read().decode("utf-8")
        st.session_state.thinking_protocol = thinking_protocol_content
        st.session_state.messages.append({"role": "user", "content": f"ğŸ“„ Thinking Protocol:\n\n{thinking_protocol_content}"})
        st.sidebar.success("Thinking Protocol ä¸Šå‚³æˆåŠŸï¼")
    except Exception as e:
        st.sidebar.error(f"è®€å– Thinking Protocol æ™‚å‡ºéŒ¯: {e}")

st.sidebar.write("ğŸ”‘ **API Key Required**:\n- Get your OpenAI API key from [OpenAI API Key Page](https://platform.openai.com/)")

st.session_state.api_key = st.sidebar.text_input(
    "Enter your OpenAI API key:", type="password", value=st.session_state.api_key
)
if st.session_state.api_key:
    client = OpenAI(api_key=st.session_state.api_key)

    uploaded_files = st.sidebar.file_uploader("Upload PDF(s)", type="pdf", accept_multiple_files=True)

    if uploaded_files:
        if st.sidebar.button("Process Documents"):
            with st.spinner("Processing documents... Please wait."):
                vector_embedding(uploaded_files)
                st.sidebar.write("âœ… Documents processed successfully!")

st.title("ğŸ“Š è²¡å ±åˆ†æ AIï¼ˆOCR & è¡¨æ ¼æå–ï¼‰")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if human_input := st.chat_input("è«‹è¼¸å…¥è²¡å ±ç›¸é—œå•é¡Œï¼ˆä¾‹å¦‚ï¼šå…¬å¸çš„æµå‹•æ¯”ç‡æ˜¯å¤šå°‘ï¼Ÿï¼‰"):
    st.session_state.messages.append({"role": "user", "content": human_input})
    with st.chat_message("user"):
        st.markdown(human_input)

    if "vectors" in st.session_state and st.session_state.vectors is not None:
        text_chunks = split_text(st.session_state.vectors)
        assistant_response = ""

        for idx, chunk in enumerate(text_chunks):
            response = client.chat.completions.create(
                model=st.session_state.selected_model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€åè²¡å‹™åˆ†æå¸«ï¼Œè² è²¬è§£è®€ PDF è²¡å ±æ•¸æ“šã€‚"},
                    {"role": "user", "content": f"**æä¾›çš„è²¡å ±å…§å®¹ï¼ˆåˆ†æ®µ {idx+1}/{len(text_chunks)}ï¼‰**:\n{chunk}\n\n**ä½¿ç”¨è€…å•é¡Œ**:\n{human_input}"}
                ]
            )
            assistant_response += response.choices[0].message.content + "\n"
        st.session_state.messages.append({"role": "assistant", "content": assistant_response})
        with st.chat_message("assistant"):
            st.markdown(assistant_response)

    else:
        st.error("è«‹å…ˆä¸Šå‚³ä¸¦è™•ç†è²¡å ± PDFï¼")
