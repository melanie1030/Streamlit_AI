import streamlit as st
import os
import tempfile
import fitz  # PyMuPDF
import pdfplumber  # æ–°å¢åº«ä¾†æå–è¡¨æ ¼
from pdf2image import convert_from_path
import pytesseract
from PIL import Image
from langchain_community.chat_models import ChatOpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import create_retrieval_chain
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

# è¨­å®š Tesseract OCR çš„è·¯å¾‘ï¼ˆWindows ç”¨æˆ¶è«‹ä¿®æ”¹è·¯å¾‘ï¼‰
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# è¨­å®š Poppler çš„è·¯å¾‘ï¼ˆç”¨æˆ¶è‡ªè¨‚ï¼‰
POPPLER_PATH = r"C:\Program Files\poppler-24.08.0\Library\bin"

def save_text_as_txt(text, filename="ocr_result.txt"):
    """ å°‡å­—ä¸²å­˜æˆ TXT æª”æ¡ˆä¸¦æä¾›ä¸‹è¼‰ """
    temp_path = os.path.join(tempfile.gettempdir(), filename)
    with open(temp_path, "w", encoding="utf-8") as file:
        file.write(text)

    with open(temp_path, "rb") as file:
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ OCR è§£æçµæœ",
            data=file,
            file_name=filename,
            mime="text/plain"
        )

def extract_text_with_ocr(pdf_path):
    """ æ··åˆ PDF æ–‡å­—æå–èˆ‡ OCRï¼Œä¸¦å„ªåŒ–è¡¨æ ¼è­˜åˆ¥ """
    doc = fitz.open(pdf_path)
    full_text = ""

    # ä½¿ç”¨ pdfplumber æå–è¡¨æ ¼ & æ–‡å­—
    with pdfplumber.open(pdf_path) as pdf:
        for i, page in enumerate(pdf.pages):
            text = page.extract_text()
            tables = page.extract_tables()

            # å¦‚æœæœ‰ç›´æ¥å¯ç”¨çš„æ–‡å­—ï¼Œå‰‡ä½¿ç”¨ pdfplumber
            if text:
                full_text += f"--- ç¬¬ {i+1} é  ---\n{text}\n\n"

            # å¦‚æœæœ‰è¡¨æ ¼ï¼Œæ ¼å¼åŒ–ä¸¦åŠ å…¥æ–‡æœ¬
            if tables:
                for table in tables:
                    formatted_table = "\n".join(
                        [" | ".join(str(cell) if cell is not None else "" for cell in row) for row in table]
                    )
                    full_text += f"--- è¡¨æ ¼ï¼ˆç¬¬ {i+1} é ï¼‰---\n{formatted_table}\n\n"

    # OCR æå–åœ–ç‰‡ä¸­çš„æ–‡æœ¬ï¼ˆé‡å°æƒæç‰ˆ PDFï¼‰
    for page in doc:
        if not page.get_text("text").strip():  # å¦‚æœ PDF å…§æ–‡å­—ç„¡æ³•æå–ï¼Œå‰‡ä½¿ç”¨ OCR
            images = convert_from_path(
                pdf_path, first_page=page.number+1, last_page=page.number+1, poppler_path=POPPLER_PATH
            )
            for img in images:
                ocr_text = pytesseract.image_to_string(
                    img, lang="eng+chi_tra", config="--psm 6"
                )
                full_text += f"--- OCR è§£æï¼ˆç¬¬ {page.number+1} é ï¼‰---\n{ocr_text}\n\n"

    return full_text


# åˆå§‹åŒ– API Key
if "api_key" not in st.session_state:
    st.session_state.api_key = ""

st.sidebar.header("Settings")

# åˆå§‹åŒ– session state è®Šæ•¸
if "messages" not in st.session_state:
    st.session_state.messages = []
if "thinking_protocol" not in st.session_state:
    st.session_state.thinking_protocol = None

# --- æ¨¡å‹é¸æ“‡ ---
OPENAI_MODELS = [
    "gpt-4-turbo", 
    "gpt-3.5-turbo-16k",
    "gpt-4",
    "gpt-4-32k",
    "gpt-4o"
]

st.sidebar.subheader("é¸æ“‡æ¨¡å‹")
selected_model = st.sidebar.selectbox("è«‹é¸æ“‡æ¨¡å‹", OPENAI_MODELS, index=0)

st.session_state.selected_model = selected_model

# --- æ¸…é™¤è¨˜æ†¶åŠŸèƒ½ ---
if st.sidebar.button("ğŸ—‘ï¸ æ¸…é™¤è¨˜æ†¶"):
    # æ¸…é™¤æ‰€æœ‰è¨˜æ†¶è®Šæ•¸
    st.session_state.memory = []
    st.session_state.messages = []
    st.session_state.thinking_protocol = None  # æ¸…é™¤ Thinking Protocol

    # é¡¯ç¤ºæˆåŠŸæç¤º
    st.sidebar.success("è¨˜æ†¶å·²æ¸…é™¤ï¼")

# --- è¨˜æ†¶ç‹€æ…‹é¡¯ç¤º ---
st.sidebar.subheader("ğŸ§  è¨˜æ†¶ç‹€æ…‹")
if st.session_state.messages:
    memory_content = "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.messages])
    st.sidebar.text_area("ç•¶å‰è¨˜æ†¶", value=memory_content, height=200)
else:
    st.sidebar.text_area("ç•¶å‰è¨˜æ†¶", value="å°šç„¡è¨Šæ¯ã€‚", height=200)

# --- Thinking Protocol ä¸Šå‚³ ---
st.sidebar.subheader("ğŸ§  ä¸Šå‚³ Thinking Protocol")
uploaded_thinking_protocol = st.sidebar.file_uploader(
    "é¸æ“‡ thinking_protocol.md æª”æ¡ˆ:", type=["md"], key="thinking_protocol_uploader"
)
if uploaded_thinking_protocol:
    try:
        thinking_protocol_content = uploaded_thinking_protocol.read().decode("utf-8")
        st.session_state.thinking_protocol = thinking_protocol_content
        st.session_state.messages.append({"role": "user", "content": f"ğŸ“„ Thinking Protocol:\n\n{thinking_protocol_content}"})
        st.sidebar.success("Thinking Protocol ä¸Šå‚³æˆåŠŸï¼")
    except Exception as e:
        st.sidebar.error(f"è®€å– Thinking Protocol æ™‚å‡ºéŒ¯: {e}")

st.sidebar.write("ğŸ”‘ **API Key Required**:\n- Get your OpenAI API key from [OpenAI API Key Page](https://platform.openai.com/)")

st.session_state.api_key = st.sidebar.text_input(
    "Enter your OpenAI API key:", type="password", value=st.session_state.api_key
)

if st.session_state.api_key:
    os.environ["OPENAI_API_KEY"] = st.session_state.api_key

    # åˆå§‹åŒ– ChatOpenAI
    llm = ChatOpenAI(api_key=st.session_state.api_key, model_name=st.session_state.selected_model)

    # è²¡å ±åˆ†æ Prompt
    prompt = ChatPromptTemplate.from_template(
        """
        ä½ æ˜¯ä¸€åè²¡å‹™åˆ†æå¸«ï¼Œè² è²¬è§£è®€ PDF è²¡å ±æ•¸æ“šã€‚

        **Step 1: æª¢ç´¢é—œéµæ•¸æ“š**
        - ä½ è¦æ ¹æ“šä»¥ä¸‹ã€Œæä¾›çš„è²¡å ±å…§å®¹ã€ä¾†å›ç­”å•é¡Œã€‚
        - å„ªå…ˆæŸ¥æ‰¾ã€Œç¾é‡‘æµé‡è¡¨ã€ã€ã€Œè³‡ç”¢è² å‚µè¡¨ã€ã€ã€Œæç›Šè¡¨ã€ä¸­çš„æ•¸æ“šã€‚
        - è‹¥å•é¡Œæ¶‰åŠè²¡å‹™æ¯”ç‡ï¼Œå‰‡éœ€è¦æ‰¾åˆ°å°æ‡‰çš„æ•¸å­—é€²è¡Œè¨ˆç®—ã€‚

        **Step 2: å˜—è©¦è¨ˆç®—è²¡å‹™æ¯”ç‡ï¼ˆå¦‚æœé©ç”¨ï¼‰**
        - **æµå‹•æ¯”ç‡ = æµå‹•è³‡ç”¢ Ã· æµå‹•è² å‚µ**
        - **è² å‚µæ¯”ç‡ = ç¸½è² å‚µ Ã· ç¸½è³‡ç”¢**
        - **è‡ªç”±ç¾é‡‘æµ = ç‡Ÿæ¥­ç¾é‡‘æµ - è³‡æœ¬æ”¯å‡º**

        **Step 3: çµ¦å‡ºå›ç­”**
        - è‹¥æœ‰æ•¸æ“šï¼Œå‰‡æä¾›è¨ˆç®—çµæœ
        - è‹¥æ•¸æ“šä¸è¶³ï¼Œå‰‡å»ºè­°ä½¿ç”¨è€…æŸ¥çœ‹ç‰¹å®šè²¡å ±éƒ¨åˆ†

        **æä¾›çš„è²¡å ±å…§å®¹**ï¼š
        {context}

        **ä½¿ç”¨è€…å•é¡Œ**ï¼š
        {input}
        """
    )

    # ä¸Šå‚³ PDF æ–‡ä»¶
    uploaded_files = st.sidebar.file_uploader("Upload PDF(s)", type="pdf", accept_multiple_files=True)
    
    
    if uploaded_files:
        if st.sidebar.button("Process Documents"):
            with st.spinner("Processing documents... Please wait."):
                
                def vector_embedding(uploaded_files):
                    if "vectors" not in st.session_state:
                        st.session_state.embeddings = OpenAIEmbeddings()
                        all_docs = []
                        combined_text = ""

                        for uploaded_file in uploaded_files:
                            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
                                temp_file.write(uploaded_file.read())
                                temp_file_path = temp_file.name

                            extracted_text = extract_text_with_ocr(temp_file_path)
                            combined_text += extracted_text + "\n\n"

                            os.remove(temp_file_path)
                            all_docs.append(extracted_text)

                        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
                        final_documents = text_splitter.create_documents(all_docs)

                        st.session_state.vectors = FAISS.from_documents(final_documents, st.session_state.embeddings)

                        save_text_as_txt(combined_text)

                vector_embedding(uploaded_files)
                st.sidebar.write("âœ… Documents processed successfully!")

# ä¸»è¦èŠå¤©ä»‹é¢
st.title("ğŸ“Š è²¡å ±åˆ†æ AIï¼ˆOCR & è¡¨æ ¼æå–ï¼‰")

# èŠå¤©è¨˜éŒ„
if "messages" not in st.session_state:
    st.session_state.messages = []

# é¡¯ç¤ºèŠå¤©æ­·å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ä½¿ç”¨è€…è¼¸å…¥å•é¡Œ
if human_input := st.chat_input("è«‹è¼¸å…¥è²¡å ±ç›¸é—œå•é¡Œï¼ˆä¾‹å¦‚ï¼šå…¬å¸çš„æµå‹•æ¯”ç‡æ˜¯å¤šå°‘ï¼Ÿï¼‰"):
    st.session_state.messages.append({"role": "user", "content": human_input})
    with st.chat_message("user"):
        st.markdown(human_input)

    if "vectors" in st.session_state and st.session_state.vectors is not None:
        document_chain = create_stuff_documents_chain(llm, prompt)
        retriever = st.session_state.vectors.as_retriever()
        retrieval_chain = create_retrieval_chain(retriever, document_chain)

        response = retrieval_chain.invoke({"input": human_input, "context": ""})
        assistant_response = response["answer"]

        st.session_state.messages.append({"role": "assistant", "content": assistant_response})
        with st.chat_message("assistant"):
            st.markdown(assistant_response)

    else:
        st.error("è«‹å…ˆä¸Šå‚³ä¸¦è™•ç†è²¡å ± PDFï¼")
